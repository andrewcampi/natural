#!/usr/bin/env python3
"""
natural: A command-line tool to convert natural language instructions into actual terminal commands
         via Groq's LLM API.
"""

import sys
import os
import subprocess
import argparse
import requests
import json
import configparser
from pathlib import Path

# Default model
DEFAULT_MODEL = "llama-3.3-70b-versatile"

# Where we'll store config (e.g. API key)
CONFIG_DIR = Path.home() / ".natural"
CONFIG_FILE = CONFIG_DIR / "config.ini"

def ensure_config_dir():
    """Ensure the config directory exists."""
    if not CONFIG_DIR.exists():
        CONFIG_DIR.mkdir(parents=True, exist_ok=True)

def load_api_key():
    """Load the API key from the config file, if it exists."""
    ensure_config_dir()
    config = configparser.ConfigParser()
    if CONFIG_FILE.exists():
        config.read(CONFIG_FILE)
        if "auth" in config and "api_key" in config["auth"]:
            return config["auth"]["api_key"]
    return None

def save_api_key(api_key):
    """Save the API key to the config file."""
    ensure_config_dir()
    config = configparser.ConfigParser()
    if CONFIG_FILE.exists():
        config.read(CONFIG_FILE)
    if "auth" not in config:
        config["auth"] = {}
    config["auth"]["api_key"] = api_key
    with open(CONFIG_FILE, "w") as f:
        config.write(f)

def is_api_key_valid(api_key):
    """Check if the provided API key is valid by calling Groq's list models endpoint,
    providing additional info if something fails."""
    if not api_key:
        print("No API key provided. Please provide your Groq API key with '--auth <API_KEY>'.")
        return False

    url = "https://api.groq.com/openai/v1/models"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }

    try:
        response = requests.get(url, headers=headers, timeout=10)
        if response.status_code == 200:
            return True
        else:
            print(f"[Error] Failed to validate API key. HTTP status: {response.status_code}")
            print(f"Response from Groq: {response.text}")
    except requests.exceptions.Timeout:
        print("[Error] Timed out while trying to validate your API key. Please check your connection or retry.")
    except requests.exceptions.ConnectionError as ce:
        print(f"[Error] Connection error while trying to validate API key: {ce}")
    except Exception as e:
        print(f"[Error] An unexpected error occurred while verifying your API key: {e}")

    return False

def fetch_models(api_key):
    """Fetch the list of models from Groq."""
    url = "https://api.groq.com/openai/v1/models"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        data = response.json()
        return [model.get("id", "unknown") for model in data.get("data", [])]
    else:
        print(f"[Error] Could not fetch models. HTTP status: {response.status_code}")
        print(f"Response from Groq: {response.text}")
    return None

def generate_command_from_prompt(api_key, prompt, model=DEFAULT_MODEL):
    """
    Query Groq's chat endpoint to generate the exact command from the user's prompt.
    We explicitly instruct the LLM not to add extra text, only the raw command.
    """
    url = "https://api.groq.com/openai/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    payload = {
        "messages": [
            {
                "role": "user",
                "content": (
                    "Provide the exact Ubuntu terminal command that achieves what the below is describing. "
                    "Do not preface your output with any other text, or provide any other text at all. "
                    "If multiple commands are required to achieve the task, string them together with '&&'. Your output should be a one-liner."
                    "The user should be able to copy/paste your output, and the command should do what they described:\n\n"
                    f"{prompt}"
                )
            }
        ],
        "model": model
    }

    try:
        response = requests.post(url, headers=headers, data=json.dumps(payload), timeout=30)
        response.raise_for_status()
        data = response.json()
        cmd = data["choices"][0]["message"]["content"].strip()
        return cmd
    except Exception as e:
        print(f"Error generating command: {e}")
        sys.exit(1)

def run_command(cmd):
    """
    Run the command in a subprocess, displaying real-time output.
    """
    try:
        print(f"Executing command: {repr(cmd)}")  # Print the exact command
        process = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
        stdout, stderr = process.communicate()
        if stdout:
            print("Output:")
            print(stdout)
        if stderr:
            print("Errors:")
            print(stderr)
        process.wait()
        print(f"Command exited with code {process.returncode}")
    except Exception as e:
        print(f"Error executing command: {e}")

def main():
    parser = argparse.ArgumentParser(
        prog="natural",
        description="A natural language to terminal command interface using Groq."
    )

    parser.add_argument("prompt", nargs="*", help="Your natural language prompt. E.g. 'copy test.txt to /tmp'")
    parser.add_argument("--auth", metavar="API_KEY", help="Provide your Groq API key. It is saved securely.")
    parser.add_argument("--list-models", action="store_true", help="List the available models.")
    parser.add_argument("--model", metavar="MODEL_NAME", help="Select the model to use from Groq.")
    parser.add_argument("--info", action="store_true", help="Show info about this Natural installation.")
    parser.add_argument("-y", action="store_true", help="Auto-accept the generation and execute immediately.")

    args = parser.parse_args()

    # Show help menu if no arguments or empty prompt
    if len(sys.argv) == 1 or (not args.auth and not args.list_models and not args.info and not args.prompt):
        parser.print_help()
        return

    # If user provides --auth
    if args.auth:
        # Save API key
        save_api_key(args.auth)
        # Immediately try to check validity
        if is_api_key_valid(args.auth):
            print("API key saved and validated successfully.")
        else:
            print("API key saved, but it might not be valid. Check with 'natural --info' or try again.")
            print("Note: Groq is geo-restricted, and might not work in all locations. Are you using a VPN?")
        return

    # Load from config
    api_key = load_api_key()

    # Check for --list-models
    if args.list_models:
        if not api_key or not is_api_key_valid(api_key):
            print("[Error] No valid API key found. Use 'natural --auth <API_KEY>' to set your key.")
            return
        models = fetch_models(api_key)
        if models is None:
            print("Could not fetch models from Groq.")
        else:
            print("Available models:")
            for m in models:
                print(f" - {m}")
        return

    # Check for --info
    if args.info:
        version = "1.0.0"  # or set dynamically
        has_key = True if api_key else False
        groq_works = is_api_key_valid(api_key) if api_key else False
        current_model = args.model if args.model else DEFAULT_MODEL
        print(f"Natural version: {version}")
        print(f"API key provided: {has_key}")
        print(f"Groq working: {groq_works}")
        print(f"Current model: {current_model}")
        return

    # Only proceed with prompt if it's not empty after stripping whitespace
    prompt_str = " ".join(args.prompt).strip()
    if not prompt_str:
        parser.print_help()
        return

    # By default, if we are about to run a prompt, we must have a valid API key
    if not api_key or not is_api_key_valid(api_key):
        print("[Error] No valid API key found. Use 'natural --auth <API_KEY>' to set your key.")
        return

    model = args.model if args.model else DEFAULT_MODEL

    # For -y usage, we print the danger line first, then proceed
    if args.y:
        print("DANGER: Auto accepting non-determininstic outputs from LLM can result in commands ")
        print("accidentally breaking or deleting things, among other catastrophic things. Use with extreme caution.")
        print("Thinking...")
    else:
        print("Thinking...")

    # Generate the command
    generated_cmd = generate_command_from_prompt(api_key, prompt_str, model=model)

    # Show the command to the user if not auto-accepting
    if not args.y:
        print("The ubuntu terminal command is:")
        print("==========")
        print(generated_cmd)
        print("=============")
        user_choice = input("Would you like me to execute that? (y/n): ").strip().lower()
        if user_choice != "y":
            print("Aborted.")
            return
    else:
        # Just confirm we printed the DANGER line and "Thinking..." line above,
        # so we can proceed silently now.
        pass

    # Execute
    print("Executing...")
    run_command(generated_cmd)

if __name__ == "__main__":
    main()
